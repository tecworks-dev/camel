
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Models &#8212; CAMEL 0.2.9 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=1b33a64c"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'key_modules/models';</script>
    <link rel="icon" href="https://raw.githubusercontent.com/camel-ai/camel/master/misc/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Message" href="messages.html" />
    <link rel="prev" title="Critic Agents and Tree Search" href="../cookbooks/critic_agents_and_tree_search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png" class="logo__image only-light" alt=""/>
    <img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">CAMEL 0.2.9</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/setup.html">API Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Agents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/embodied_agents.html">Embodied Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/critic_agents_and_tree_search.html">Critic Agents and Tree Search</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Key Modules</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="messages.html">Message</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="prompts.html">Prompt</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="storages.html">Storages</a></li>
<li class="toctree-l1"><a class="reference internal" href="society.html">Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="embeddings.html">Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrievers.html">Retrievers</a></li>
<li class="toctree-l1"><a class="reference internal" href="workforce.html">Workforce</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cookbooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_society.html">Society Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/model_speed_comparison.html">Model Speed Comparison Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_message.html">Message Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_tools.html">Tools Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_tools_from_Composio.html">Using Tools from Composio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_memory.html">Memory Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_rag.html">RAG Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_prompting.html">Prompting Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/task_generation.html">Task Generation Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/knowledge_graph.html">Graph RAG Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/roleplaying_scraper.html">Role-Playing Scraper for Report &amp; Knowledge Graph Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/video_analysis.html">Video Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_tracking.html">Track CAMEL Agents with AgentOps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/workforce_judge_committee.html">Create A Hackathon Judge Committee with Workforce</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules.html">camel</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../camel.html">camel package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.agents.html">camel.agents package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.agents.tool_agents.html">camel.agents.tool_agents package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.configs.html">camel.configs package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.embeddings.html">camel.embeddings package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.interpreters.html">camel.interpreters package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.loaders.html">camel.loaders package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.memories.html">camel.memories package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.memories.blocks.html">camel.memories.blocks package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.memories.context_creators.html">camel.memories.context_creators package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.messages.html">camel.messages package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.models.html">camel.models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.prompts.html">camel.prompts package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.responses.html">camel.responses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.retrievers.html">camel.retrievers package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.societies.html">camel.societies package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.societies.workforce.html">camel.societies.workforce package</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.storages.html">camel.storages package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.graph_storages.html">camel.storages.graph_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.key_value_storages.html">camel.storages.key_value_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.object_storages.html">camel.storages.object_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.vectordb_storages.html">camel.storages.vectordb_storages package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.tasks.html">camel.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.terminators.html">camel.terminators package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.toolkits.html">camel.toolkits package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.types.html">camel.types package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.utils.html">camel.utils package</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/key_modules/models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concept">1. Concept</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-model-platforms">2. Supported Model Platforms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-models-by-api-calling">3. Using Models by API calling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-on-device-open-source-models">4. Using On-Device Open Source Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama-to-set-llama-3-locally">4.1 Using Ollama to Set Llama 3 Locally</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-vllm-to-set-phi-3-locally">4.2 Using vLLM to Set Phi-3 Locally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-model-speed">5. About Model Speed</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">6. Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="models">
<h1>Models<a class="headerlink" href="#models" title="Link to this heading">#</a></h1>
<section id="concept">
<h2>1. Concept<a class="headerlink" href="#concept" title="Link to this heading">#</a></h2>
<p>The model is the brain of the intelligent agent, responsible for processing all input and output data. By calling different models, the agent can execute operations such as text analysis, image recognition, or complex reasoning according to task requirements. CAMEL offers a range of standard and customizable interfaces, as well as seamless integrations with various components, to facilitate the development of applications with Large Language Models (LLMs). In this part, we will introduce models currently supported by CAMEL and the working principles and interaction methods with models.</p>
<p>All the codes are also available on colab notebook <a class="reference external" href="https://colab.research.google.com/drive/18hQLpte6WW2Ja3Yfj09NRiVY-6S2MFu7?usp=sharing">here</a>.</p>
</section>
<section id="supported-model-platforms">
<h2>2. Supported Model Platforms<a class="headerlink" href="#supported-model-platforms" title="Link to this heading">#</a></h2>
<p>The following table lists currently supported model platforms by CAMEL.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model Platform</p></th>
<th class="head"><p>Available Models</p></th>
<th class="head"><p>Multi-modality</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>gpt-4o</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI</p></td>
<td><p>gpt-4o-mini</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>o1-preview</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI</p></td>
<td><p>o1-mini</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>gpt-4-turbo</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI</p></td>
<td><p>gpt-4</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>gpt-3.5-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Azure OpenAI</p></td>
<td><p>gpt-4o</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Azure OpenAI</p></td>
<td><p>gpt-4-turbo</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Azure OpenAI</p></td>
<td><p>gpt-4</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Azure OpenAI</p></td>
<td><p>gpt-3.5-turbo</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI Compatible</p></td>
<td><p>Depends on the provider</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>mistral-large-2</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>pixtral-12b-2409</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>ministral-8b-latest</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>ministral-3b-latest</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>open-mistral-nemo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>codestral</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>open-mistral-7b</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>open-mixtral-8x7b</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>open-mixtral-8x22b</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>open-codestral-mamba</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Anthropic</p></td>
<td><p>claude-3-5-sonnet-20240620</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Anthropic</p></td>
<td><p>claude-3-haiku-20240307</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Anthropic</p></td>
<td><p>claude-3-sonnet-20240229</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Anthropic</p></td>
<td><p>claude-3-opus-20240229</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Anthropic</p></td>
<td><p>claude-2.0</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Gemini</p></td>
<td><p>gemini-1.5-pro</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Gemini</p></td>
<td><p>ggemini-1.5-flash</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Lingyiwanwu</p></td>
<td><p>yi-lightning</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Lingyiwanwu</p></td>
<td><p>yi-large</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Lingyiwanwu</p></td>
<td><p>yi-medium</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Lingyiwanwu</p></td>
<td><p>yi-large-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Lingyiwanwu</p></td>
<td><p>yi-vision</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Lingyiwanwu</p></td>
<td><p>yi-medium-200k</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Lingyiwanwu</p></td>
<td><p>yi-spark</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Lingyiwanwu</p></td>
<td><p>yi-large-rag</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Lingyiwanwu</p></td>
<td><p>yi-large-fc</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Qwen</p></td>
<td><p>qwen-max</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Qwen</p></td>
<td><p>qwen-plus</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Qwen</p></td>
<td><p>qwen-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Qwen</p></td>
<td><p>qwen-long</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Qwen</p></td>
<td><p>qwen-vl-max</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Qwen</p></td>
<td><p>qwen-vl-plus</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Qwen</p></td>
<td><p>qwen-math-plus</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Qwen</p></td>
<td><p>qwen-math-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Qwen</p></td>
<td><p>qwen-coder-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>ZhipuAI</p></td>
<td><p>glm-4v</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>ZhipuAI</p></td>
<td><p>glm-4</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>ZhipuAI</p></td>
<td><p>glm-3-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Reka</p></td>
<td><p>reka-core</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Reka</p></td>
<td><p>reka-flash</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Reka</p></td>
<td><p>reka-edge</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Nividia</p></td>
<td><p>nemotron-4-340b-reward</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>SambaNova</p></td>
<td><p>https://community.sambanova.ai/t/supported-models/193</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-odd"><td><p>Groq</p></td>
<td><p>https://console.groq.com/docs/models</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-even"><td><p>Ollama</p></td>
<td><p>https://ollama.com/library</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-odd"><td><p>vLLM</p></td>
<td><p>https://docs.vllm.ai/en/latest/models/supported_models.html</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-even"><td><p>Together AI</p></td>
<td><p>https://docs.together.ai/docs/chat-models</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-odd"><td><p>LiteLLM</p></td>
<td><p>https://docs.litellm.ai/docs/providers</p></td>
<td><p>—–</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="using-models-by-api-calling">
<h2>3. Using Models by API calling<a class="headerlink" href="#using-models-by-api-calling" title="Link to this heading">#</a></h2>
<p>Here is an example code to use a specific model (gpt-4o-mini). If you want to use another model, you can simply change these three parameters: <code class="docutils literal notranslate"><span class="pre">model_platform</span></code>, <code class="docutils literal notranslate"><span class="pre">model_type</span></code>, <code class="docutils literal notranslate"><span class="pre">model_config_dict</span></code> .</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">camel.models</span> <span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span> <span class="nn">camel.types</span> <span class="kn">import</span> <span class="n">ModelPlatformType</span><span class="p">,</span> <span class="n">ModelType</span>
<span class="kn">from</span> <span class="nn">camel.configs</span> <span class="kn">import</span> <span class="n">ChatGPTConfig</span>
<span class="kn">from</span> <span class="nn">camel.messages</span> <span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span> <span class="nn">camel.agents</span> <span class="kn">import</span> <span class="n">ChatAgent</span>

<span class="c1"># Define the model, here in this case we use gpt-4o-mini</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OPENAI</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="n">ModelType</span><span class="o">.</span><span class="n">GPT_4O_MINI</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="n">ChatGPTConfig</span><span class="p">()</span><span class="o">.</span><span class="n">as_dict</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># Define an assitant message</span>
<span class="n">system_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="c1"># Initialize the agent</span>
<span class="n">ChatAgent</span><span class="p">(</span><span class="n">system_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>And if you want to use an OpenAI-compatible API, you can replace the <code class="docutils literal notranslate"><span class="pre">model</span></code> with the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OPENAI_COMPATIBLE_MODEL</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;a-string-representing-the-model-type&quot;</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_COMPATIBILIY_API_KEY&quot;</span><span class="p">),</span>
    <span class="n">url</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_COMPATIBILIY_API_BASE_URL&quot;</span><span class="p">),</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-on-device-open-source-models">
<h2>4. Using On-Device Open Source Models<a class="headerlink" href="#using-on-device-open-source-models" title="Link to this heading">#</a></h2>
<p>In the current landscape, for those seeking highly stable content generation, OpenAI’s gpt-4o-mini, gpt-4o are often recommended. However, the field is rich with many other outstanding open-source models that also yield commendable results. CAMEL can support developers to delve into integrating these open-source large language models (LLMs) to achieve project outputs based on unique input ideas.</p>
<section id="using-ollama-to-set-llama-3-locally">
<h3>4.1 Using Ollama to Set Llama 3 Locally<a class="headerlink" href="#using-ollama-to-set-llama-3-locally" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Download <a class="reference external" href="https://ollama.com/download">Ollama</a>.</p></li>
<li><p>After setting up Ollama, pull the Llama3 model by typing the following command into the terminal:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span>pull<span class="w"> </span>llama3
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> similar the one below in your project directory. (Optional)</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FROM</span> <span class="n">llama3</span>

<span class="c1"># Set parameters</span>
<span class="n">PARAMETER</span> <span class="n">temperature</span> <span class="mf">0.8</span>
<span class="n">PARAMETER</span> <span class="n">stop</span> <span class="n">Result</span>

<span class="c1"># Sets a custom system message to specify the behavior of the chat assistant</span>
<span class="c1"># Leaving it blank for now.</span>

<span class="n">SYSTEM</span> <span class="s2">&quot;&quot;&quot; &quot;&quot;&quot;</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Create a script to get the base model (llama3) and create a custom model using the <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> above. Save this as a <code class="docutils literal notranslate"><span class="pre">.sh</span></code> file: (Optional)</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/zsh

# variables
model_name=&quot;llama3&quot;
custom_model_name=&quot;camel-llama3&quot;

#get the base model
ollama pull $model_name

#create the model file
ollama create $custom_model_name -f ./Llama3ModelFile
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Navigate to the directory where the script and <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> are located and run the script. Enjoy your Llama3 model, enhanced by CAMEL’s excellent agents.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">camel.agents</span> <span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span> <span class="nn">camel.messages</span> <span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span> <span class="nn">camel.models</span> <span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span> <span class="nn">camel.types</span> <span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">ollama_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OLLAMA</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;llama3&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://localhost:11434/v1&quot;</span><span class="p">,</span> <span class="c1"># Optional</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">agent_sys_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">agent_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">ollama_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="s2">&quot;Say hi to CAMEL&quot;</span>

<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-vllm-to-set-phi-3-locally">
<h3>4.2 Using vLLM to Set Phi-3 Locally<a class="headerlink" href="#using-vllm-to-set-phi-3-locally" title="Link to this heading">#</a></h3>
<p>Install <a class="reference external" href="https://docs.vllm.ai/en/latest/getting_started/installation.html">vLLM</a> first.</p>
<p>After setting up vLLM, start an OpenAI compatible server for example by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">vllm</span><span class="o">.</span><span class="n">entrypoints</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">api_server</span> <span class="o">--</span><span class="n">model</span> <span class="n">microsoft</span><span class="o">/</span><span class="n">Phi</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="n">mini</span><span class="o">-</span><span class="mi">4</span><span class="n">k</span><span class="o">-</span><span class="n">instruct</span> <span class="o">--</span><span class="n">api</span><span class="o">-</span><span class="n">key</span> <span class="n">vllm</span> <span class="o">--</span><span class="n">dtype</span> <span class="n">bfloat16</span>
</pre></div>
</div>
<p>Create and run following script (more details please refer to this <a class="reference external" href="https://github.com/camel-ai/camel/blob/master/examples/models/vllm_model_example.py">example</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">camel.agents</span> <span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span> <span class="nn">camel.messages</span> <span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span> <span class="nn">camel.models</span> <span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span> <span class="nn">camel.types</span> <span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">vllm_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">VLLM</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;microsoft/Phi-3-mini-4k-instruct&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://localhost:8000/v1&quot;</span><span class="p">,</span> <span class="c1"># Optional</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="n">agent_sys_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">agent_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">vllm_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="s2">&quot;Say hi to CAMEL AI&quot;</span>

<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="about-model-speed">
<h2>5. About Model Speed<a class="headerlink" href="#about-model-speed" title="Link to this heading">#</a></h2>
<p>Model speed is a crucial factor in AI application performance. It affects both user experience and system efficiency, especially in real-time or interactive tasks. In <a class="reference internal" href="../cookbooks/model_speed_comparison.html"><span class="std std-doc">this notebook</span></a>, we compared several models, including OpenAI’s GPT-4O Mini, GPT-4O, O1 Preview, and SambaNova’s Llama series, by measuring the number of tokens each model processes per second.</p>
<p>Key Insights:
Smaller models like SambaNova’s Llama 8B and OpenAI’s GPT-4O Mini typically offer faster responses.
Larger models like SambaNova’s Llama 405B, while more powerful, tend to generate output more slowly due to their complexity.
OpenAI models demonstrate relatively consistent performance, while SambaNova’s Llama 8B significantly outperforms others in speed.
The chart below illustrates the tokens per second achieved by each model during our tests:</p>
<p><img alt="Model Speed Comparison" src="https://i.postimg.cc/4xByytyZ/model-speed.png" /></p>
</section>
<section id="conclusion">
<h2>6. Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In conclusion, CAMEL empowers developers to explore and integrate these diverse models, unlocking new possibilities for innovative AI applications. The world of large language models offers a rich tapestry of options beyond just the well-known proprietary solutions. By guiding users through model selection, environment setup, and integration, CAMEL bridges the gap between cutting-edge AI research and practical implementation. Its hybrid approach, combining in-house implementations with third-party integrations, offers unparalleled flexibility and comprehensive support for LLM-based development. Don’t just watch this transformation that is happening from the sidelines.</p>
<p>Dive into the CAMEL documentation, experiment with different models, and be part of shaping the future of AI. The era of truly flexible and powerful AI is here - are you ready to make your mark?</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../cookbooks/critic_agents_and_tree_search.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Critic Agents and Tree Search</p>
      </div>
    </a>
    <a class="right-next"
       href="messages.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Message</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concept">1. Concept</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-model-platforms">2. Supported Model Platforms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-models-by-api-calling">3. Using Models by API calling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-on-device-open-source-models">4. Using On-Device Open Source Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama-to-set-llama-3-locally">4.1 Using Ollama to Set Llama 3 Locally</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-vllm-to-set-phi-3-locally">4.2 Using vLLM to Set Phi-3 Locally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-model-speed">5. About Model Speed</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">6. Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By CAMEL-AI.org
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, CAMEL-AI.org.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>