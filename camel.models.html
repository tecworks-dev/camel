
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>camel.models package &#8212; CAMEL 0.2.9 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=1b33a64c"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'camel.models';</script>
    <link rel="icon" href="https://raw.githubusercontent.com/camel-ai/camel/master/misc/favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="camel.prompts package" href="camel.prompts.html" />
    <link rel="prev" title="camel.messages package" href="camel.messages.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png" class="logo__image only-light" alt=""/>
    <img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">CAMEL 0.2.9</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="get_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="get_started/setup.html">API Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Agents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="cookbooks/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/embodied_agents.html">Embodied Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/critic_agents_and_tree_search.html">Critic Agents and Tree Search</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Key Modules</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="key_modules/models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/messages.html">Message</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/prompts.html">Prompt</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/tasks.html">Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/loaders.html">Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/storages.html">Storages</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/society.html">Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/embeddings.html">Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/retrievers.html">Retrievers</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_modules/workforce.html">Workforce</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cookbooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="cookbooks/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_society.html">Society Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/model_speed_comparison.html">Model Speed Comparison Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_message.html">Message Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_with_tools.html">Tools Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_with_tools_from_Composio.html">Using Tools from Composio</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_with_memory.html">Memory Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_with_rag.html">RAG Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_prompting.html">Prompting Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/task_generation.html">Task Generation Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/knowledge_graph.html">Graph RAG Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/roleplaying_scraper.html">Role-Playing Scraper for Report &amp; Knowledge Graph Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/video_analysis.html">Video Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/agents_tracking.html">Track CAMEL Agents with AgentOps</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbooks/workforce_judge_committee.html">Create A Hackathon Judge Committee with Workforce</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="modules.html">camel</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="camel.html">camel package</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 has-children"><a class="reference internal" href="camel.agents.html">camel.agents package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="camel.agents.tool_agents.html">camel.agents.tool_agents package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="camel.configs.html">camel.configs package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.embeddings.html">camel.embeddings package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.interpreters.html">camel.interpreters package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.loaders.html">camel.loaders package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="camel.memories.html">camel.memories package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="camel.memories.blocks.html">camel.memories.blocks package</a></li>
<li class="toctree-l4"><a class="reference internal" href="camel.memories.context_creators.html">camel.memories.context_creators package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="camel.messages.html">camel.messages package</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">camel.models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.prompts.html">camel.prompts package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.responses.html">camel.responses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.retrievers.html">camel.retrievers package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="camel.societies.html">camel.societies package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="camel.societies.workforce.html">camel.societies.workforce package</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="camel.storages.html">camel.storages package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="camel.storages.graph_storages.html">camel.storages.graph_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="camel.storages.key_value_storages.html">camel.storages.key_value_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="camel.storages.object_storages.html">camel.storages.object_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="camel.storages.vectordb_storages.html">camel.storages.vectordb_storages package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="camel.tasks.html">camel.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.terminators.html">camel.terminators package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.toolkits.html">camel.toolkits package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.types.html">camel.types package</a></li>
<li class="toctree-l3"><a class="reference internal" href="camel.utils.html">camel.utils package</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/camel.models.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>camel.models package</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.anthropic_model">camel.models.anthropic_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel"><code class="docutils literal notranslate"><span class="pre">AnthropicModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.count_tokens_from_prompt"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.count_tokens_from_prompt()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.run"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.stream"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.azure_openai_model">camel.models.azure_openai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.base_model">camel.models.base_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.check_model_config"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.count_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.count_tokens_from_messages()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.run"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.stream"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.token_counter"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_counter</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.token_limit"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_limit</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.gemini_model">camel.models.gemini_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel"><code class="docutils literal notranslate"><span class="pre">GeminiModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GeminiModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.run"><code class="docutils literal notranslate"><span class="pre">GeminiModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.stream"><code class="docutils literal notranslate"><span class="pre">GeminiModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.to_gemini_req"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_gemini_req()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.to_openai_response"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_openai_response()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GeminiModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.groq_model">camel.models.groq_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel"><code class="docutils literal notranslate"><span class="pre">GroqModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GroqModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.run"><code class="docutils literal notranslate"><span class="pre">GroqModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.stream"><code class="docutils literal notranslate"><span class="pre">GroqModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GroqModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.litellm_model">camel.models.litellm_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel.run"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.mistral_model">camel.models.mistral_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel"><code class="docutils literal notranslate"><span class="pre">MistralModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">MistralModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.run"><code class="docutils literal notranslate"><span class="pre">MistralModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.stream"><code class="docutils literal notranslate"><span class="pre">MistralModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.token_counter"><code class="docutils literal notranslate"><span class="pre">MistralModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.model_factory">camel.models.model_factory module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.model_factory.ModelFactory"><code class="docutils literal notranslate"><span class="pre">ModelFactory</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.model_factory.ModelFactory.create"><code class="docutils literal notranslate"><span class="pre">ModelFactory.create()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.nemotron_model">camel.models.nemotron_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel"><code class="docutils literal notranslate"><span class="pre">NemotronModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">NemotronModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel.run"><code class="docutils literal notranslate"><span class="pre">NemotronModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel.token_counter"><code class="docutils literal notranslate"><span class="pre">NemotronModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.ollama_model">camel.models.ollama_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel"><code class="docutils literal notranslate"><span class="pre">OllamaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OllamaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.run"><code class="docutils literal notranslate"><span class="pre">OllamaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.stream"><code class="docutils literal notranslate"><span class="pre">OllamaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OllamaModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.openai_audio_models">camel.models.open_source_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_audio_models.OpenAIAudioModels"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_audio_models.OpenAIAudioModels.speech_to_text"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.speech_to_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_audio_models.OpenAIAudioModels.text_to_speech"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.text_to_speech()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.openai_compatible_model">camel.models.openai_compatible_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.openai_model">camel.models.openai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel"><code class="docutils literal notranslate"><span class="pre">OpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.reka_model">camel.models.reka_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel"><code class="docutils literal notranslate"><span class="pre">RekaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">RekaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.run"><code class="docutils literal notranslate"><span class="pre">RekaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.stream"><code class="docutils literal notranslate"><span class="pre">RekaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">RekaModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.samba_model">camel.models.samba_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel"><code class="docutils literal notranslate"><span class="pre">SambaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">SambaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.run"><code class="docutils literal notranslate"><span class="pre">SambaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.stream"><code class="docutils literal notranslate"><span class="pre">SambaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">SambaModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.stub_model">camel.models.stub_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel"><code class="docutils literal notranslate"><span class="pre">StubModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">StubModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.model_type"><code class="docutils literal notranslate"><span class="pre">StubModel.model_type</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.run"><code class="docutils literal notranslate"><span class="pre">StubModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.token_counter"><code class="docutils literal notranslate"><span class="pre">StubModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubTokenCounter"><code class="docutils literal notranslate"><span class="pre">StubTokenCounter</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubTokenCounter.count_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">StubTokenCounter.count_tokens_from_messages()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.togetherai_model">camel.models.togetherai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.run"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.stream"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.vllm_model">camel.models.vllm_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel"><code class="docutils literal notranslate"><span class="pre">VLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">VLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.run"><code class="docutils literal notranslate"><span class="pre">VLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.stream"><code class="docutils literal notranslate"><span class="pre">VLLMModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">VLLMModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.zhipuai_model">camel.models.zhipuai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.run"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.stream"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel"><code class="docutils literal notranslate"><span class="pre">AnthropicModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.count_tokens_from_prompt"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.count_tokens_from_prompt()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.run"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.stream"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.check_model_config"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.count_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.count_tokens_from_messages()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.run"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.stream"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.token_counter"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_counter</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.token_limit"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_limit</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel"><code class="docutils literal notranslate"><span class="pre">GeminiModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GeminiModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.run"><code class="docutils literal notranslate"><span class="pre">GeminiModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.stream"><code class="docutils literal notranslate"><span class="pre">GeminiModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.to_gemini_req"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_gemini_req()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.to_openai_response"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_openai_response()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GeminiModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel"><code class="docutils literal notranslate"><span class="pre">GroqModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GroqModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.run"><code class="docutils literal notranslate"><span class="pre">GroqModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.stream"><code class="docutils literal notranslate"><span class="pre">GroqModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GroqModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel.run"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel"><code class="docutils literal notranslate"><span class="pre">MistralModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">MistralModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.run"><code class="docutils literal notranslate"><span class="pre">MistralModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.stream"><code class="docutils literal notranslate"><span class="pre">MistralModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.token_counter"><code class="docutils literal notranslate"><span class="pre">MistralModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ModelFactory"><code class="docutils literal notranslate"><span class="pre">ModelFactory</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ModelFactory.create"><code class="docutils literal notranslate"><span class="pre">ModelFactory.create()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel"><code class="docutils literal notranslate"><span class="pre">NemotronModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">NemotronModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel.run"><code class="docutils literal notranslate"><span class="pre">NemotronModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel.token_counter"><code class="docutils literal notranslate"><span class="pre">NemotronModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel"><code class="docutils literal notranslate"><span class="pre">OllamaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OllamaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.run"><code class="docutils literal notranslate"><span class="pre">OllamaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.stream"><code class="docutils literal notranslate"><span class="pre">OllamaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OllamaModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIAudioModels"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIAudioModels.speech_to_text"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.speech_to_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIAudioModels.text_to_speech"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.text_to_speech()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel"><code class="docutils literal notranslate"><span class="pre">OpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel"><code class="docutils literal notranslate"><span class="pre">QwenModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">QwenModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.run"><code class="docutils literal notranslate"><span class="pre">QwenModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.stream"><code class="docutils literal notranslate"><span class="pre">QwenModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.token_counter"><code class="docutils literal notranslate"><span class="pre">QwenModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel"><code class="docutils literal notranslate"><span class="pre">RekaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">RekaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.run"><code class="docutils literal notranslate"><span class="pre">RekaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.stream"><code class="docutils literal notranslate"><span class="pre">RekaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">RekaModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel"><code class="docutils literal notranslate"><span class="pre">SambaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">SambaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.run"><code class="docutils literal notranslate"><span class="pre">SambaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.stream"><code class="docutils literal notranslate"><span class="pre">SambaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">SambaModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel"><code class="docutils literal notranslate"><span class="pre">StubModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">StubModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.model_type"><code class="docutils literal notranslate"><span class="pre">StubModel.model_type</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.run"><code class="docutils literal notranslate"><span class="pre">StubModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.token_counter"><code class="docutils literal notranslate"><span class="pre">StubModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.run"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.stream"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel"><code class="docutils literal notranslate"><span class="pre">VLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">VLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.run"><code class="docutils literal notranslate"><span class="pre">VLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.stream"><code class="docutils literal notranslate"><span class="pre">VLLMModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">VLLMModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel"><code class="docutils literal notranslate"><span class="pre">YiModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">YiModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.run"><code class="docutils literal notranslate"><span class="pre">YiModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.stream"><code class="docutils literal notranslate"><span class="pre">YiModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.token_counter"><code class="docutils literal notranslate"><span class="pre">YiModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.run"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.stream"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="camel-models-package">
<h1>camel.models package<a class="headerlink" href="#camel-models-package" title="Link to this heading">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">#</a></h2>
</section>
<section id="module-camel.models.anthropic_model">
<span id="camel-models-anthropic-model-module"></span><h2>camel.models.anthropic_model module<a class="headerlink" href="#module-camel.models.anthropic_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.anthropic_model.AnthropicModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.anthropic_model.</span></span><span class="sig-name descname"><span class="pre">AnthropicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.anthropic_model.AnthropicModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Anthropic API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of CLAUDE_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into Anthropic.messages.create().  If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">AnthropicConfig().as_dict()</span></code> will be used.
(default:<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Anthropic service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Anthropic service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">AnthropicTokenCounter</span></code>
will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.anthropic_model.AnthropicModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.anthropic_model.AnthropicModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration is valid for anthropic
model backends.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API, or it does not contain
    <code class="xref py py-obj docutils literal notranslate"><span class="pre">model_path</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">server_url</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.anthropic_model.AnthropicModel.count_tokens_from_prompt">
<span class="sig-name descname"><span class="pre">count_tokens_from_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel.count_tokens_from_prompt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.anthropic_model.AnthropicModel.count_tokens_from_prompt" title="Link to this definition">#</a></dt>
<dd><p>Count the number of tokens from a prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>)  The prompt string.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The number of tokens in the prompt.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.anthropic_model.AnthropicModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.anthropic_model.AnthropicModel.run" title="Link to this definition">#</a></dt>
<dd><p>Run inference of Anthropic chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Response in the OpenAI API format.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.anthropic_model.AnthropicModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.anthropic_model.AnthropicModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.anthropic_model.AnthropicModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.anthropic_model.AnthropicModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.azure_openai_model">
<span id="camel-models-azure-openai-model-module"></span><h2>camel.models.azure_openai_model module<a class="headerlink" href="#module-camel.models.azure_openai_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.azure_openai_model.AzureOpenAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.azure_openai_model.</span></span><span class="sig-name descname"><span class="pre">AzureOpenAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">azure_deployment_name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/azure_openai_model.html#AzureOpenAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.azure_openai_model.AzureOpenAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Azure OpenAI API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of GPT_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ChatGPTConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the OpenAI service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the OpenAI service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_version</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The api version for the model.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>azure_deployment_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The deployment name
you chose when you deployed an azure model. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code>
will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/">https://learn.microsoft.com/en-us/azure/ai-services/openai/</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.azure_openai_model.AzureOpenAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/azure_openai_model.html#AzureOpenAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.azure_openai_model.AzureOpenAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Azure OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Azure OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.azure_openai_model.AzureOpenAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/azure_openai_model.html#AzureOpenAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.azure_openai_model.AzureOpenAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Azure OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.azure_openai_model.AzureOpenAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.azure_openai_model.AzureOpenAIModel.stream" title="Link to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Returns whether the model is in stream mode,</dt><dd><p>which sends partial results each time.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.azure_openai_model.AzureOpenAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.azure_openai_model.AzureOpenAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.base_model">
<span id="camel-models-base-model-module"></span><h2>camel.models.base_model module<a class="headerlink" href="#module-camel.models.base_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.base_model.</span></span><span class="sig-name descname"><span class="pre">BaseModelBackend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.base_model.BaseModelBackend" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Base class for different model backends.
It may be OpenAI API, a local LLM, a stub for unit tests, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A config
dictionary. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">{}</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the model service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token
counter to use for the model. If not provided,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend.check_model_config">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.base_model.BaseModelBackend.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the input model configuration contains unexpected
arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected argument for this model class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend.count_tokens_from_messages">
<span class="sig-name descname"><span class="pre">count_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend.count_tokens_from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.base_model.BaseModelBackend.count_tokens_from_messages" title="Link to this definition">#</a></dt>
<dd><p>Count the number of tokens in the messages using the specific
tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>Dict</em><em>]</em>)  message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Number of tokens in the messages.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend.run">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.base_model.BaseModelBackend.run" title="Link to this definition">#</a></dt>
<dd><p>Runs the query to the backend model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.base_model.BaseModelBackend.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend.token_counter">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.base_model.BaseModelBackend.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.base_model.BaseModelBackend.token_limit">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_limit</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#camel.models.base_model.BaseModelBackend.token_limit" title="Link to this definition">#</a></dt>
<dd><p>Returns the maximum token limit for a given model.</p>
<p>This method retrieves the maximum token limit either from the
<cite>model_config_dict</cite> or from the models default token limit.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The maximum token limit for the given model.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.gemini_model">
<span id="camel-models-gemini-model-module"></span><h2>camel.models.gemini_model module<a class="headerlink" href="#module-camel.models.gemini_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.gemini_model.</span></span><span class="sig-name descname"><span class="pre">GeminiModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.gemini_model.GeminiModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Gemini API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>genai.GenerativeModel.generate_content()
`. If:obj:`None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">GeminiConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the gemini service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the gemini service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">GeminiTokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Currently <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;stream&quot;:</span> <span class="pre">True</span></code> is not supported with Gemini due to the
limitation of the current camel design.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.gemini_model.GeminiModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Gemini API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.gemini_model.GeminiModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Gemini model.
This method can handle multimodal input</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong>  Message list or Message with the chat history
in OpenAi format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A ChatCompletion object formatted for the OpenAI API.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>response</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.gemini_model.GeminiModel.stream" title="Link to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Returns whether the model is in stream mode,</dt><dd><p>which sends partial results each time.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel.to_gemini_req">
<span class="sig-name descname"><span class="pre">to_gemini_req</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ContentsType</span></span></span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.to_gemini_req"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.gemini_model.GeminiModel.to_gemini_req" title="Link to this definition">#</a></dt>
<dd><p>Converts the request from the OpenAI API format to the Gemini API
request format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong>  The request object from the OpenAI API.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of messages formatted for Gemini API.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>converted_messages</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel.to_openai_response">
<span class="sig-name descname"><span class="pre">to_openai_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">response</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">GenerateContentResponse</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.to_openai_response"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.gemini_model.GeminiModel.to_openai_response" title="Link to this definition">#</a></dt>
<dd><p>Converts the response from the Gemini API to the OpenAI API
response format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>response</strong>  The response object returned by the Gemini API</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A ChatCompletion object formatted for</dt><dd><p>the OpenAI API.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>openai_response</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.gemini_model.GeminiModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.gemini_model.GeminiModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.groq_model">
<span id="camel-models-groq-model-module"></span><h2>camel.models.groq_model module<a class="headerlink" href="#module-camel.models.groq_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.groq_model.GroqModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.groq_model.</span></span><span class="sig-name descname"><span class="pre">GroqModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/groq_model.html#GroqModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.groq_model.GroqModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>LLM API served by Groq in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">GroqConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the Groq service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>).</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Groq service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.groq_model.GroqModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/groq_model.html#GroqModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.groq_model.GroqModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any unexpected
arguments to Groq API. But Groq API does not have any additional
arguments to check.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Groq API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.groq_model.GroqModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/groq_model.html#GroqModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.groq_model.GroqModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.groq_model.GroqModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.groq_model.GroqModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model supports streaming. But Groq API does
not support streaming.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.groq_model.GroqModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.groq_model.GroqModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.litellm_model">
<span id="camel-models-litellm-model-module"></span><h2>camel.models.litellm_model module<a class="headerlink" href="#module-camel.models.litellm_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.litellm_model.LiteLLMModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.litellm_model.</span></span><span class="sig-name descname"><span class="pre">LiteLLMModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/litellm_model.html#LiteLLMModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.litellm_model.LiteLLMModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Constructor for LiteLLM backend with OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, such as GPT-3.5-turbo, Claude-2, etc.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">LiteLLMConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the model service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">LiteLLMTokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.litellm_model.LiteLLMModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/litellm_model.html#LiteLLMModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.litellm_model.LiteLLMModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any unexpected
arguments to LiteLLM API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.litellm_model.LiteLLMModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/litellm_model.html#LiteLLMModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.litellm_model.LiteLLMModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of LiteLLM chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.litellm_model.LiteLLMModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.litellm_model.LiteLLMModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.mistral_model">
<span id="camel-models-mistral-model-module"></span><h2>camel.models.mistral_model module<a class="headerlink" href="#module-camel.models.mistral_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.mistral_model.MistralModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.mistral_model.</span></span><span class="sig-name descname"><span class="pre">MistralModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/mistral_model.html#MistralModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.mistral_model.MistralModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Mistral API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of MISTRAL_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>Mistral.chat.complete()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">MistralConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the mistral service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the mistral service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.mistral_model.MistralModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/mistral_model.html#MistralModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.mistral_model.MistralModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Mistral API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Mistral API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.mistral_model.MistralModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/mistral_model.html#MistralModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.mistral_model.MistralModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Mistral chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.mistral_model.MistralModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.mistral_model.MistralModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time. Current its not supported.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.mistral_model.MistralModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.mistral_model.MistralModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<p># NOTE: Temporarily using <cite>OpenAITokenCounter</cite> due to a current issue
# with installing <cite>mistral-common</cite> alongside <cite>mistralai</cite>.
# Refer to: <a class="github reference external" href="https://github.com/mistralai/mistral-common/issues/37">mistralai/mistral-common#37</a></p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.model_factory">
<span id="camel-models-model-factory-module"></span><h2>camel.models.model_factory module<a class="headerlink" href="#module-camel.models.model_factory" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.model_factory.ModelFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.model_factory.</span></span><span class="sig-name descname"><span class="pre">ModelFactory</span></span><a class="reference internal" href="_modules/camel/models/model_factory.html#ModelFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.model_factory.ModelFactory" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Factory of backend models.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  in case the provided model type is unknown.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.model_factory.ModelFactory.create">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_platform:</span> <span class="pre">~camel.types.enums.ModelPlatformType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><span class="pre">BaseModelBackend</span></a></span></span><a class="reference internal" href="_modules/camel/models/model_factory.html#ModelFactory.create"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.model_factory.ModelFactory.create" title="Link to this definition">#</a></dt>
<dd><p>Creates an instance of <cite>BaseModelBackend</cite> of the specified type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_platform</strong> (<a class="reference internal" href="camel.types.html#camel.types.enums.ModelPlatformType" title="camel.types.enums.ModelPlatformType"><em>ModelPlatformType</em></a>)  Platform from which the model
originates.</p></li>
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a
backend is created. Can be a <cite>str</cite> for open source platforms.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>)  A dictionary that will be fed
into the backend constructor. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token
counter to use for the model. If not provided,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(ModelType.GPT_4O_MINI)</span></code>
will be used if the model platform didnt provide official
token counter. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the model service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The initialized backend.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend">BaseModelBackend</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong>  If there is no backend for the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.nemotron_model">
<span id="camel-models-nemotron-model-module"></span><h2>camel.models.nemotron_model module<a class="headerlink" href="#module-camel.models.nemotron_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.nemotron_model.NemotronModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.nemotron_model.</span></span><span class="sig-name descname"><span class="pre">NemotronModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/nemotron_model.html#NemotronModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.nemotron_model.NemotronModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Nemotron model API backend with OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Nvidia service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Nvidia service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://integrate.api.nvidia.com/v1</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Nemotron model doesnt support additional model config like OpenAI.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.nemotron_model.NemotronModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/nemotron_model.html#NemotronModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.nemotron_model.NemotronModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the input model configuration contains unexpected
arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected argument for this model class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.nemotron_model.NemotronModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/nemotron_model.html#NemotronModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.nemotron_model.NemotronModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.nemotron_model.NemotronModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.nemotron_model.NemotronModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.ollama_model">
<span id="camel-models-ollama-model-module"></span><h2>camel.models.ollama_model module<a class="headerlink" href="#module-camel.models.ollama_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.ollama_model.OllamaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.ollama_model.</span></span><span class="sig-name descname"><span class="pre">OllamaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/ollama_model.html#OllamaModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ollama_model.OllamaModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Ollama service interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OllamaConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the model service.  Ollama doesnt need API key, it would be
ignored if set. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="github reference external" href="https://github.com/ollama/ollama/blob/main/docs/openai.md">ollama/ollama</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.ollama_model.OllamaModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/ollama_model.html#OllamaModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ollama_model.OllamaModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Ollama API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.ollama_model.OllamaModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/ollama_model.html#OllamaModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ollama_model.OllamaModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.ollama_model.OllamaModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.ollama_model.OllamaModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.ollama_model.OllamaModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.ollama_model.OllamaModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.openai_audio_models">
<span id="camel-models-open-source-model-module"></span><h2>camel.models.open_source_model module<a class="headerlink" href="#module-camel.models.openai_audio_models" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.openai_audio_models.OpenAIAudioModels">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.openai_audio_models.</span></span><span class="sig-name descname"><span class="pre">OpenAIAudioModels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_audio_models.html#OpenAIAudioModels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_audio_models.OpenAIAudioModels" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Provides access to OpenAIs Text-to-Speech (TTS) and Speech_to_Text
(STT) models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.openai_audio_models.OpenAIAudioModels.speech_to_text">
<span class="sig-name descname"><span class="pre">speech_to_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio_file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translate_into_english</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="_modules/camel/models/openai_audio_models.html#OpenAIAudioModels.speech_to_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_audio_models.OpenAIAudioModels.speech_to_text" title="Link to this definition">#</a></dt>
<dd><p>Convert speech audio to text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>audio_file_path</strong> (<em>str</em>)  The audio file path, supporting one of
these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or
webm.</p></li>
<li><p><strong>translate_into_english</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to translate the
speech into English. Defaults to <cite>False</cite>.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>)  Extra keyword arguments passed to the
Speech-to-Text (STT) API.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output text.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong>  If the audio file format is not supported.</p></li>
<li><p><strong>Exception</strong>  If theres an error during the STT API call.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.openai_audio_models.OpenAIAudioModels.text_to_speech">
<span class="sig-name descname"><span class="pre">text_to_speech</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="camel.types.html#camel.types.enums.AudioModelType" title="camel.types.enums.AudioModelType"><span class="pre">AudioModelType</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">AudioModelType.TTS_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voice</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="camel.types.html#camel.types.enums.VoiceType" title="camel.types.enums.VoiceType"><span class="pre">VoiceType</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">VoiceType.ALLOY</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">HttpxBinaryResponseContent</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">HttpxBinaryResponseContent</span></span></span><a class="reference internal" href="_modules/camel/models/openai_audio_models.html#OpenAIAudioModels.text_to_speech"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_audio_models.OpenAIAudioModels.text_to_speech" title="Link to this definition">#</a></dt>
<dd><p>Convert text to speech using OpenAIs TTS model. This method
converts the given input text to speech using the specified model and
voice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>str</em>)  The text to be converted to speech.</p></li>
<li><p><strong>model_type</strong> (<a class="reference internal" href="camel.types.html#camel.types.enums.AudioModelType" title="camel.types.enums.AudioModelType"><em>AudioModelType</em></a><em>, </em><em>optional</em>)  The TTS model to use.
Defaults to <cite>AudioModelType.TTS_1</cite>.</p></li>
<li><p><strong>voice</strong> (<a class="reference internal" href="camel.types.html#camel.types.enums.VoiceType" title="camel.types.enums.VoiceType"><em>VoiceType</em></a><em>, </em><em>optional</em>)  The voice to be used for generating
speech. Defaults to <cite>VoiceType.ALLOY</cite>.</p></li>
<li><p><strong>storage_path</strong> (<em>str</em><em>, </em><em>optional</em>)  The local path to store the
generated speech file if provided, defaults to <cite>None</cite>.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>)  Extra kwargs passed to the TTS API.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Union[List[_legacy_response.HttpxBinaryResponseContent],</dt><dd><p>_legacy_response.HttpxBinaryResponseContent]: List of response
content object from OpenAI if input charaters more than 4096,
single response content if input charaters less than 4096.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Exception</strong>  If theres an error during the TTS API call.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.openai_compatible_model">
<span id="camel-models-openai-compatible-model-module"></span><h2>camel.models.openai_compatible_model module<a class="headerlink" href="#module-camel.models.openai_compatible_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.openai_compatible_model.OpenAICompatibleModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.openai_compatible_model.</span></span><span class="sig-name descname"><span class="pre">OpenAICompatibleModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_compatible_model.html#OpenAICompatibleModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_compatible_model.OpenAICompatibleModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Constructor for model backend supporting OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">{}</span></code> will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>)  The API key for authenticating with the model service.</p></li>
<li><p><strong>url</strong> (<em>str</em>)  The url to the model service.</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.openai_compatible_model.OpenAICompatibleModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_compatible_model.html#OpenAICompatibleModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the input model configuration contains unexpected
arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected argument for this model class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.openai_compatible_model.OpenAICompatibleModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/openai_compatible_model.html#OpenAICompatibleModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.openai_compatible_model.OpenAICompatibleModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.openai_compatible_model.OpenAICompatibleModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.openai_model">
<span id="camel-models-openai-model-module"></span><h2>camel.models.openai_model module<a class="headerlink" href="#module-camel.models.openai_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.openai_model.OpenAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.openai_model.</span></span><span class="sig-name descname"><span class="pre">OpenAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_model.html#OpenAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_model.OpenAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>OpenAI API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of GPT_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ChatGPTConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the OpenAI service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the OpenAI service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.openai_model.OpenAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_model.html#OpenAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_model.OpenAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.openai_model.OpenAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/openai_model.html#OpenAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.openai_model.OpenAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.openai_model.OpenAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.openai_model.OpenAIModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.openai_model.OpenAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.openai_model.OpenAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.reka_model">
<span id="camel-models-reka-model-module"></span><h2>camel.models.reka_model module<a class="headerlink" href="#module-camel.models.reka_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.reka_model.RekaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.reka_model.</span></span><span class="sig-name descname"><span class="pre">RekaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/reka_model.html#RekaModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.reka_model.RekaModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Reka API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of REKA_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>Reka.chat.create()</cite>. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">RekaConfig().as_dict()</span></code> will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Reka service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Reka service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.reka_model.RekaModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/reka_model.html#RekaModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.reka_model.RekaModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Reka API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Reka API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.reka_model.RekaModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/reka_model.html#RekaModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.reka_model.RekaModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Mistral chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.reka_model.RekaModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.reka_model.RekaModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.reka_model.RekaModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.reka_model.RekaModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<p># NOTE: Temporarily using <cite>OpenAITokenCounter</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.samba_model">
<span id="camel-models-samba-model-module"></span><h2>camel.models.samba_model module<a class="headerlink" href="#module-camel.models.samba_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.samba_model.SambaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.samba_model.</span></span><span class="sig-name descname"><span class="pre">SambaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/samba_model.html#SambaModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.samba_model.SambaModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>SambaNova service interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a SambaNova backend
is created. Supported models via SambaNova Cloud:
<cite>https://community.sambanova.ai/t/supported-models/193</cite>.
Supported models via SambaVerse API is listed in
<cite>https://sambaverse.sambanova.ai/models</cite>.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">SambaCloudAPIConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the SambaNova service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the SambaNova service.
Current support SambaVerse API:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;https://sambaverse.sambanova.ai/api/predict&quot;</span></code> and
SambaNova Cloud:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;https://api.sambanova.ai/v1&quot;</span></code> (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://api.</span>
<span class="pre">sambanova.ai/v1</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.samba_model.SambaModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/samba_model.html#SambaModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.samba_model.SambaModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to SambaNova API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to SambaNova API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.samba_model.SambaModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/samba_model.html#SambaModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.samba_model.SambaModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs SambaNovas service.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.samba_model.SambaModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.samba_model.SambaModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.samba_model.SambaModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.samba_model.SambaModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.stub_model">
<span id="camel-models-stub-model-module"></span><h2>camel.models.stub_model module<a class="headerlink" href="#module-camel.models.stub_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.stub_model.StubModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.stub_model.</span></span><span class="sig-name descname"><span class="pre">StubModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.stub_model.StubModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>A dummy model used for unit tests.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.stub_model.StubModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.stub_model.StubModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Directly pass the check on arguments to STUB model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="camel.models.stub_model.StubModel.model_type">
<span class="sig-name descname"><span class="pre">model_type</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.UnifiedModelType" title="camel.types.UnifiedModelType"><span class="pre">UnifiedModelType</span></a></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">ModelType.STUB</span></em><a class="headerlink" href="#camel.models.stub_model.StubModel.model_type" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.stub_model.StubModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.stub_model.StubModel.run" title="Link to this definition">#</a></dt>
<dd><p>Run fake inference by returning a fixed string.
All arguments are unused for the dummy model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Response in the OpenAI API format.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.stub_model.StubModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.stub_model.StubModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.stub_model.StubTokenCounter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.stub_model.</span></span><span class="sig-name descname"><span class="pre">StubTokenCounter</span></span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubTokenCounter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.stub_model.StubTokenCounter" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenCounter</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.stub_model.StubTokenCounter.count_tokens_from_messages">
<span class="sig-name descname"><span class="pre">count_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubTokenCounter.count_tokens_from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.stub_model.StubTokenCounter.count_tokens_from_messages" title="Link to this definition">#</a></dt>
<dd><p>Token counting for STUB models, directly returning a constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A constant to act as the number of the tokens in the</dt><dd><p>messages.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.togetherai_model">
<span id="camel-models-togetherai-model-module"></span><h2>camel.models.togetherai_model module<a class="headerlink" href="#module-camel.models.togetherai_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.togetherai_model.TogetherAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.togetherai_model.</span></span><span class="sig-name descname"><span class="pre">TogetherAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/togetherai_model.html#TogetherAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.togetherai_model.TogetherAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Constructor for Together AI backend with OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, supported model can be found here:
<a class="reference external" href="https://docs.together.ai/docs/chat-models">https://docs.together.ai/docs/chat-models</a></p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">TogetherAIConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Together service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Together AI service.
If not provided, <a class="reference external" href="https://api.together.xyz/v1">https://api.together.xyz/v1</a> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.togetherai_model.TogetherAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/togetherai_model.html#TogetherAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.togetherai_model.TogetherAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to TogetherAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to TogetherAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.togetherai_model.TogetherAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/togetherai_model.html#TogetherAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.togetherai_model.TogetherAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.togetherai_model.TogetherAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.togetherai_model.TogetherAIModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.togetherai_model.TogetherAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.togetherai_model.TogetherAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.vllm_model">
<span id="camel-models-vllm-model-module"></span><h2>camel.models.vllm_model module<a class="headerlink" href="#module-camel.models.vllm_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.vllm_model.VLLMModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.vllm_model.</span></span><span class="sig-name descname"><span class="pre">VLLMModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/vllm_model.html#VLLMModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.vllm_model.VLLMModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>vLLM service interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the model service. vLLM doesnt need API key, it would be ignored
if set. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service. If not
provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;http://localhost:8000/v1&quot;</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html">https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.vllm_model.VLLMModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/vllm_model.html#VLLMModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.vllm_model.VLLMModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to vLLM API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.vllm_model.VLLMModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/vllm_model.html#VLLMModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.vllm_model.VLLMModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.vllm_model.VLLMModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.vllm_model.VLLMModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.vllm_model.VLLMModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.vllm_model.VLLMModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models.zhipuai_model">
<span id="camel-models-zhipuai-model-module"></span><h2>camel.models.zhipuai_model module<a class="headerlink" href="#module-camel.models.zhipuai_model" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.zhipuai_model.ZhipuAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.zhipuai_model.</span></span><span class="sig-name descname"><span class="pre">ZhipuAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/zhipuai_model.html#ZhipuAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.zhipuai_model.ZhipuAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>ZhipuAI API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of GLM_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ZhipuAIConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the ZhipuAI service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the ZhipuAI service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://open.bigmodel.cn/api/paas/v4/</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.zhipuai_model.ZhipuAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/zhipuai_model.html#ZhipuAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.zhipuai_model.ZhipuAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to ZhipuAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.zhipuai_model.ZhipuAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/zhipuai_model.html#ZhipuAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.zhipuai_model.ZhipuAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.zhipuai_model.ZhipuAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.zhipuai_model.ZhipuAIModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.zhipuai_model.ZhipuAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.zhipuai_model.ZhipuAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-camel.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-camel.models" title="Link to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="camel.models.AnthropicModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">AnthropicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AnthropicModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Anthropic API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of CLAUDE_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into Anthropic.messages.create().  If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">AnthropicConfig().as_dict()</span></code> will be used.
(default:<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Anthropic service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Anthropic service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">AnthropicTokenCounter</span></code>
will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.AnthropicModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AnthropicModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration is valid for anthropic
model backends.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API, or it does not contain
    <code class="xref py py-obj docutils literal notranslate"><span class="pre">model_path</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">server_url</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.AnthropicModel.count_tokens_from_prompt">
<span class="sig-name descname"><span class="pre">count_tokens_from_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel.count_tokens_from_prompt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AnthropicModel.count_tokens_from_prompt" title="Link to this definition">#</a></dt>
<dd><p>Count the number of tokens from a prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>)  The prompt string.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The number of tokens in the prompt.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.AnthropicModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/anthropic_model.html#AnthropicModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AnthropicModel.run" title="Link to this definition">#</a></dt>
<dd><p>Run inference of Anthropic chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Response in the OpenAI API format.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.AnthropicModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.AnthropicModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.AnthropicModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.AnthropicModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.AzureOpenAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">AzureOpenAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">azure_deployment_name:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/azure_openai_model.html#AzureOpenAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AzureOpenAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Azure OpenAI API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of GPT_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ChatGPTConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the OpenAI service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the OpenAI service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_version</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The api version for the model.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>azure_deployment_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The deployment name
you chose when you deployed an azure model. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code>
will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/">https://learn.microsoft.com/en-us/azure/ai-services/openai/</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.AzureOpenAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/azure_openai_model.html#AzureOpenAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AzureOpenAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Azure OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Azure OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.AzureOpenAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/azure_openai_model.html#AzureOpenAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.AzureOpenAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Azure OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.AzureOpenAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.AzureOpenAIModel.stream" title="Link to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Returns whether the model is in stream mode,</dt><dd><p>which sends partial results each time.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.AzureOpenAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.AzureOpenAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">BaseModelBackend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.BaseModelBackend" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Base class for different model backends.
It may be OpenAI API, a local LLM, a stub for unit tests, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A config
dictionary. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">{}</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the model service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token
counter to use for the model. If not provided,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend.check_model_config">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.BaseModelBackend.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the input model configuration contains unexpected
arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected argument for this model class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend.count_tokens_from_messages">
<span class="sig-name descname"><span class="pre">count_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend.count_tokens_from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.BaseModelBackend.count_tokens_from_messages" title="Link to this definition">#</a></dt>
<dd><p>Count the number of tokens in the messages using the specific
tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>Dict</em><em>]</em>)  message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Number of tokens in the messages.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend.run">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/base_model.html#BaseModelBackend.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.BaseModelBackend.run" title="Link to this definition">#</a></dt>
<dd><p>Runs the query to the backend model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.BaseModelBackend.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend.token_counter">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.BaseModelBackend.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.BaseModelBackend.token_limit">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_limit</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#camel.models.BaseModelBackend.token_limit" title="Link to this definition">#</a></dt>
<dd><p>Returns the maximum token limit for a given model.</p>
<p>This method retrieves the maximum token limit either from the
<cite>model_config_dict</cite> or from the models default token limit.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The maximum token limit for the given model.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.GeminiModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">GeminiModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GeminiModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Gemini API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>genai.GenerativeModel.generate_content()
`. If:obj:`None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">GeminiConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the gemini service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the gemini service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">GeminiTokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Currently <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;stream&quot;:</span> <span class="pre">True</span></code> is not supported with Gemini due to the
limitation of the current camel design.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.GeminiModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GeminiModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Gemini API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.GeminiModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GeminiModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Gemini model.
This method can handle multimodal input</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong>  Message list or Message with the chat history
in OpenAi format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A ChatCompletion object formatted for the OpenAI API.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>response</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.GeminiModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.GeminiModel.stream" title="Link to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Returns whether the model is in stream mode,</dt><dd><p>which sends partial results each time.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.GeminiModel.to_gemini_req">
<span class="sig-name descname"><span class="pre">to_gemini_req</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ContentsType</span></span></span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.to_gemini_req"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GeminiModel.to_gemini_req" title="Link to this definition">#</a></dt>
<dd><p>Converts the request from the OpenAI API format to the Gemini API
request format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong>  The request object from the OpenAI API.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of messages formatted for Gemini API.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>converted_messages</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.GeminiModel.to_openai_response">
<span class="sig-name descname"><span class="pre">to_openai_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">response</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">GenerateContentResponse</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/gemini_model.html#GeminiModel.to_openai_response"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GeminiModel.to_openai_response" title="Link to this definition">#</a></dt>
<dd><p>Converts the response from the Gemini API to the OpenAI API
response format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>response</strong>  The response object returned by the Gemini API</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A ChatCompletion object formatted for</dt><dd><p>the OpenAI API.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>openai_response</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.GeminiModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.GeminiModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.GroqModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">GroqModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/groq_model.html#GroqModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GroqModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>LLM API served by Groq in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">GroqConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the Groq service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>).</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Groq service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.GroqModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/groq_model.html#GroqModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GroqModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any unexpected
arguments to Groq API. But Groq API does not have any additional
arguments to check.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Groq API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.GroqModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/groq_model.html#GroqModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.GroqModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.GroqModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.GroqModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model supports streaming. But Groq API does
not support streaming.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.GroqModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.GroqModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.LiteLLMModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">LiteLLMModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/litellm_model.html#LiteLLMModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.LiteLLMModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Constructor for LiteLLM backend with OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, such as GPT-3.5-turbo, Claude-2, etc.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">LiteLLMConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the model service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">LiteLLMTokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.LiteLLMModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/litellm_model.html#LiteLLMModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.LiteLLMModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any unexpected
arguments to LiteLLM API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.LiteLLMModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/litellm_model.html#LiteLLMModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.LiteLLMModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of LiteLLM chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.LiteLLMModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.LiteLLMModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.MistralModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">MistralModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/mistral_model.html#MistralModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.MistralModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Mistral API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of MISTRAL_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>Mistral.chat.complete()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">MistralConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the mistral service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the mistral service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.MistralModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/mistral_model.html#MistralModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.MistralModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Mistral API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Mistral API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.MistralModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/mistral_model.html#MistralModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.MistralModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Mistral chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.MistralModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.MistralModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time. Current its not supported.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.MistralModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.MistralModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<p># NOTE: Temporarily using <cite>OpenAITokenCounter</cite> due to a current issue
# with installing <cite>mistral-common</cite> alongside <cite>mistralai</cite>.
# Refer to: <a class="github reference external" href="https://github.com/mistralai/mistral-common/issues/37">mistralai/mistral-common#37</a></p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.ModelFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">ModelFactory</span></span><a class="reference internal" href="_modules/camel/models/model_factory.html#ModelFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ModelFactory" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Factory of backend models.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  in case the provided model type is unknown.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.ModelFactory.create">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_platform:</span> <span class="pre">~camel.types.enums.ModelPlatformType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><span class="pre">BaseModelBackend</span></a></span></span><a class="reference internal" href="_modules/camel/models/model_factory.html#ModelFactory.create"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ModelFactory.create" title="Link to this definition">#</a></dt>
<dd><p>Creates an instance of <cite>BaseModelBackend</cite> of the specified type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_platform</strong> (<a class="reference internal" href="camel.types.html#camel.types.enums.ModelPlatformType" title="camel.types.enums.ModelPlatformType"><em>ModelPlatformType</em></a>)  Platform from which the model
originates.</p></li>
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a
backend is created. Can be a <cite>str</cite> for open source platforms.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>)  A dictionary that will be fed
into the backend constructor. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token
counter to use for the model. If not provided,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(ModelType.GPT_4O_MINI)</span></code>
will be used if the model platform didnt provide official
token counter. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the model service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The initialized backend.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#camel.models.BaseModelBackend" title="camel.models.BaseModelBackend">BaseModelBackend</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong>  If there is no backend for the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.NemotronModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">NemotronModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/nemotron_model.html#NemotronModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.NemotronModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Nemotron model API backend with OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Nvidia service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Nvidia service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://integrate.api.nvidia.com/v1</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Nemotron model doesnt support additional model config like OpenAI.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.NemotronModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/nemotron_model.html#NemotronModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.NemotronModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the input model configuration contains unexpected
arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected argument for this model class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.NemotronModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/nemotron_model.html#NemotronModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.NemotronModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.NemotronModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.NemotronModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.OllamaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">OllamaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/ollama_model.html#OllamaModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OllamaModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Ollama service interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>.
If:obj:<cite>None</cite>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OllamaConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the model service.  Ollama doesnt need API key, it would be
ignored if set. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="github reference external" href="https://github.com/ollama/ollama/blob/main/docs/openai.md">ollama/ollama</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OllamaModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/ollama_model.html#OllamaModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OllamaModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Ollama API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OllamaModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/ollama_model.html#OllamaModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OllamaModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.OllamaModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.OllamaModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.OllamaModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.OllamaModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.OpenAIAudioModels">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">OpenAIAudioModels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_audio_models.html#OpenAIAudioModels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAIAudioModels" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Provides access to OpenAIs Text-to-Speech (TTS) and Speech_to_Text
(STT) models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OpenAIAudioModels.speech_to_text">
<span class="sig-name descname"><span class="pre">speech_to_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio_file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translate_into_english</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="_modules/camel/models/openai_audio_models.html#OpenAIAudioModels.speech_to_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAIAudioModels.speech_to_text" title="Link to this definition">#</a></dt>
<dd><p>Convert speech audio to text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>audio_file_path</strong> (<em>str</em>)  The audio file path, supporting one of
these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or
webm.</p></li>
<li><p><strong>translate_into_english</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to translate the
speech into English. Defaults to <cite>False</cite>.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>)  Extra keyword arguments passed to the
Speech-to-Text (STT) API.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output text.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong>  If the audio file format is not supported.</p></li>
<li><p><strong>Exception</strong>  If theres an error during the STT API call.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OpenAIAudioModels.text_to_speech">
<span class="sig-name descname"><span class="pre">text_to_speech</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="camel.types.html#camel.types.enums.AudioModelType" title="camel.types.enums.AudioModelType"><span class="pre">AudioModelType</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">AudioModelType.TTS_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voice</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="camel.types.html#camel.types.enums.VoiceType" title="camel.types.enums.VoiceType"><span class="pre">VoiceType</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">VoiceType.ALLOY</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">HttpxBinaryResponseContent</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">HttpxBinaryResponseContent</span></span></span><a class="reference internal" href="_modules/camel/models/openai_audio_models.html#OpenAIAudioModels.text_to_speech"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAIAudioModels.text_to_speech" title="Link to this definition">#</a></dt>
<dd><p>Convert text to speech using OpenAIs TTS model. This method
converts the given input text to speech using the specified model and
voice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>str</em>)  The text to be converted to speech.</p></li>
<li><p><strong>model_type</strong> (<a class="reference internal" href="camel.types.html#camel.types.enums.AudioModelType" title="camel.types.enums.AudioModelType"><em>AudioModelType</em></a><em>, </em><em>optional</em>)  The TTS model to use.
Defaults to <cite>AudioModelType.TTS_1</cite>.</p></li>
<li><p><strong>voice</strong> (<a class="reference internal" href="camel.types.html#camel.types.enums.VoiceType" title="camel.types.enums.VoiceType"><em>VoiceType</em></a><em>, </em><em>optional</em>)  The voice to be used for generating
speech. Defaults to <cite>VoiceType.ALLOY</cite>.</p></li>
<li><p><strong>storage_path</strong> (<em>str</em><em>, </em><em>optional</em>)  The local path to store the
generated speech file if provided, defaults to <cite>None</cite>.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>)  Extra kwargs passed to the TTS API.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Union[List[_legacy_response.HttpxBinaryResponseContent],</dt><dd><p>_legacy_response.HttpxBinaryResponseContent]: List of response
content object from OpenAI if input charaters more than 4096,
single response content if input charaters less than 4096.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Exception</strong>  If theres an error during the TTS API call.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.OpenAICompatibleModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">OpenAICompatibleModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_compatible_model.html#OpenAICompatibleModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAICompatibleModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Constructor for model backend supporting OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">{}</span></code> will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>)  The API key for authenticating with the model service.</p></li>
<li><p><strong>url</strong> (<em>str</em>)  The url to the model service.</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OpenAICompatibleModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_compatible_model.html#OpenAICompatibleModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAICompatibleModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the input model configuration contains unexpected
arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected argument for this model class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OpenAICompatibleModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/openai_compatible_model.html#OpenAICompatibleModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAICompatibleModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.OpenAICompatibleModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.OpenAICompatibleModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.OpenAICompatibleModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.OpenAICompatibleModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.OpenAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">OpenAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_model.html#OpenAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>OpenAI API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of GPT_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ChatGPTConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the OpenAI service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the OpenAI service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OpenAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/openai_model.html#OpenAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.OpenAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/openai_model.html#OpenAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.OpenAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.OpenAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.OpenAIModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.OpenAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.OpenAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.QwenModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">QwenModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/qwen_model.html#QwenModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.QwenModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Qwen API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of Qwen series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">QwenConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Qwen service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Qwen service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://dashscope.aliyuncs.com/compatible-mode/v1</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.QwenModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/qwen_model.html#QwenModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.QwenModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Qwen API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Qwen API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.QwenModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/qwen_model.html#QwenModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.QwenModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Qwen chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.QwenModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.QwenModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.QwenModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.QwenModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.RekaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">RekaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/reka_model.html#RekaModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.RekaModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Reka API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of REKA_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>Reka.chat.create()</cite>. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">RekaConfig().as_dict()</span></code> will be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Reka service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Reka service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter</span></code> will
be used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.RekaModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/reka_model.html#RekaModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.RekaModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Reka API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Reka API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.RekaModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a></span></span><a class="reference internal" href="_modules/camel/models/reka_model.html#RekaModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.RekaModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Mistral chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ChatCompletion.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.RekaModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.RekaModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.RekaModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.RekaModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<p># NOTE: Temporarily using <cite>OpenAITokenCounter</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.SambaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">SambaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/samba_model.html#SambaModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.SambaModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>SambaNova service interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a SambaNova backend
is created. Supported models via SambaNova Cloud:
<cite>https://community.sambanova.ai/t/supported-models/193</cite>.
Supported models via SambaVerse API is listed in
<cite>https://sambaverse.sambanova.ai/models</cite>.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">SambaCloudAPIConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating
with the SambaNova service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the SambaNova service.
Current support SambaVerse API:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;https://sambaverse.sambanova.ai/api/predict&quot;</span></code> and
SambaNova Cloud:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;https://api.sambanova.ai/v1&quot;</span></code> (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://api.</span>
<span class="pre">sambanova.ai/v1</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.SambaModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/samba_model.html#SambaModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.SambaModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to SambaNova API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to SambaNova API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.SambaModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/samba_model.html#SambaModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.SambaModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs SambaNovas service.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.SambaModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.SambaModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.SambaModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.SambaModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.StubModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">StubModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.StubModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>A dummy model used for unit tests.</p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.StubModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.StubModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Directly pass the check on arguments to STUB model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="camel.models.StubModel.model_type">
<span class="sig-name descname"><span class="pre">model_type</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.UnifiedModelType" title="camel.types.UnifiedModelType"><span class="pre">UnifiedModelType</span></a></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">ModelType.STUB</span></em><a class="headerlink" href="#camel.models.StubModel.model_type" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.StubModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/stub_model.html#StubModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.StubModel.run" title="Link to this definition">#</a></dt>
<dd><p>Run fake inference by returning a fixed string.
All arguments are unused for the dummy model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Response in the OpenAI API format.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.StubModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.StubModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.TogetherAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">TogetherAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/togetherai_model.html#TogetherAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.TogetherAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Constructor for Together AI backend with OpenAI compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, supported model can be found here:
<a class="reference external" href="https://docs.together.ai/docs/chat-models">https://docs.together.ai/docs/chat-models</a></p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">TogetherAIConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Together service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Together AI service.
If not provided, <a class="reference external" href="https://api.together.xyz/v1">https://api.together.xyz/v1</a> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.TogetherAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/togetherai_model.html#TogetherAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.TogetherAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to TogetherAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to TogetherAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.TogetherAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/togetherai_model.html#TogetherAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.TogetherAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.TogetherAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.TogetherAIModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.TogetherAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.TogetherAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.VLLMModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">VLLMModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/vllm_model.html#VLLMModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.VLLMModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>vLLM service interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">VLLMConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the model service. vLLM doesnt need API key, it would be ignored
if set. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the model service. If not
provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;http://localhost:8000/v1&quot;</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html">https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.VLLMModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/vllm_model.html#VLLMModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.VLLMModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to vLLM API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to OpenAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.VLLMModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/vllm_model.html#VLLMModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.VLLMModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.VLLMModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.VLLMModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.VLLMModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.VLLMModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter">BaseTokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.YiModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">YiModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/yi_model.html#YiModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.YiModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>Yi API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of Yi series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">YiConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the Yi service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the Yi service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://api.lingyiwanwu.com/v1</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.YiModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/yi_model.html#YiModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.YiModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to Yi API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to Yi API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.YiModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/yi_model.html#YiModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.YiModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of Yi chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.YiModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.YiModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.YiModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.YiModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="camel.models.ZhipuAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">camel.models.</span></span><span class="sig-name descname"><span class="pre">ZhipuAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">~&lt;unknown&gt;.ModelType</span> <span class="pre">|</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_config_dict:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_counter:</span> <span class="pre">~camel.utils.token_counting.BaseTokenCounter</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/zhipuai_model.html#ZhipuAIModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ZhipuAIModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#camel.models.base_model.BaseModelBackend" title="camel.models.base_model.BaseModelBackend"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a></p>
<p>ZhipuAI API in a unified BaseModelBackend interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_type</strong> (<em>Union</em><em>[</em><a class="reference internal" href="camel.types.html#camel.types.ModelType" title="camel.types.ModelType"><em>ModelType</em></a><em>, </em><em>str</em><em>]</em>)  Model for which a backend is
created, one of GLM_* series.</p></li>
<li><p><strong>model_config_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A dictionary
that will be fed into:obj:<cite>openai.ChatCompletion.create()</cite>. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ZhipuAIConfig().as_dict()</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The API key for authenticating with
the ZhipuAI service. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The url to the ZhipuAI service.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">https://open.bigmodel.cn/api/paas/v4/</span></code>)</p></li>
<li><p><strong>token_counter</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><em>BaseTokenCounter</em></a><em>]</em><em>, </em><em>optional</em>)  Token counter to
use for the model. If not provided, <code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenAITokenCounter(</span>
<span class="pre">ModelType.GPT_4O_MINI)</span></code> will be used.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="camel.models.ZhipuAIModel.check_model_config">
<span class="sig-name descname"><span class="pre">check_model_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/camel/models/zhipuai_model.html#ZhipuAIModel.check_model_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ZhipuAIModel.check_model_config" title="Link to this definition">#</a></dt>
<dd><p>Check whether the model configuration contains any
unexpected arguments to OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong>  If the model configuration dictionary contains any
    unexpected arguments to ZhipuAI API.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="camel.models.ZhipuAIModel.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionSystemMessageParam" title="openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam"><span class="pre">ChatCompletionSystemMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionUserMessageParam" title="openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam"><span class="pre">ChatCompletionUserMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionAssistantMessageParam" title="openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam"><span class="pre">ChatCompletionAssistantMessageParam</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ChatCompletionToolMessageParam</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionFunctionMessageParam" title="openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam"><span class="pre">ChatCompletionFunctionMessageParam</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="openai.types.chat.chat_completion.ChatCompletion"><span class="pre">ChatCompletion</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Stream</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="openai.types.chat.chat_completion_chunk.ChatCompletionChunk"><span class="pre">ChatCompletionChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/camel/models/zhipuai_model.html#ZhipuAIModel.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#camel.models.ZhipuAIModel.run" title="Link to this definition">#</a></dt>
<dd><p>Runs inference of OpenAI chat completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><em>OpenAIMessage</em><em>]</em>)  Message list with the chat history
in OpenAI API format.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>ChatCompletion</cite> in the non-stream mode, or
<cite>Stream[ChatCompletionChunk]</cite> in the stream mode.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletion" title="camel.types.ChatCompletion">ChatCompletion</a>, Stream[<a class="reference internal" href="camel.types.html#camel.types.ChatCompletionChunk" title="camel.types.ChatCompletionChunk">ChatCompletionChunk</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.ZhipuAIModel.stream">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#camel.models.ZhipuAIModel.stream" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the model is in stream mode, which sends partial
results each time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether the model is in stream mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="camel.models.ZhipuAIModel.token_counter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token_counter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.BaseTokenCounter" title="camel.utils.token_counting.BaseTokenCounter"><span class="pre">BaseTokenCounter</span></a></em><a class="headerlink" href="#camel.models.ZhipuAIModel.token_counter" title="Link to this definition">#</a></dt>
<dd><p>Initialize the token counter for the model backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The token counter following the models</dt><dd><p>tokenization style.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="camel.utils.html#camel.utils.token_counting.OpenAITokenCounter" title="camel.utils.token_counting.OpenAITokenCounter">OpenAITokenCounter</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="camel.messages.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">camel.messages package</p>
      </div>
    </a>
    <a class="right-next"
       href="camel.prompts.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">camel.prompts package</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.anthropic_model">camel.models.anthropic_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel"><code class="docutils literal notranslate"><span class="pre">AnthropicModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.count_tokens_from_prompt"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.count_tokens_from_prompt()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.run"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.stream"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.anthropic_model.AnthropicModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.azure_openai_model">camel.models.azure_openai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.azure_openai_model.AzureOpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.base_model">camel.models.base_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.check_model_config"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.count_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.count_tokens_from_messages()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.run"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.stream"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.token_counter"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_counter</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.base_model.BaseModelBackend.token_limit"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_limit</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.gemini_model">camel.models.gemini_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel"><code class="docutils literal notranslate"><span class="pre">GeminiModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GeminiModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.run"><code class="docutils literal notranslate"><span class="pre">GeminiModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.stream"><code class="docutils literal notranslate"><span class="pre">GeminiModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.to_gemini_req"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_gemini_req()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.to_openai_response"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_openai_response()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.gemini_model.GeminiModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GeminiModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.groq_model">camel.models.groq_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel"><code class="docutils literal notranslate"><span class="pre">GroqModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GroqModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.run"><code class="docutils literal notranslate"><span class="pre">GroqModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.stream"><code class="docutils literal notranslate"><span class="pre">GroqModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.groq_model.GroqModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GroqModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.litellm_model">camel.models.litellm_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel.run"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.litellm_model.LiteLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.mistral_model">camel.models.mistral_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel"><code class="docutils literal notranslate"><span class="pre">MistralModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">MistralModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.run"><code class="docutils literal notranslate"><span class="pre">MistralModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.stream"><code class="docutils literal notranslate"><span class="pre">MistralModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.mistral_model.MistralModel.token_counter"><code class="docutils literal notranslate"><span class="pre">MistralModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.model_factory">camel.models.model_factory module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.model_factory.ModelFactory"><code class="docutils literal notranslate"><span class="pre">ModelFactory</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.model_factory.ModelFactory.create"><code class="docutils literal notranslate"><span class="pre">ModelFactory.create()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.nemotron_model">camel.models.nemotron_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel"><code class="docutils literal notranslate"><span class="pre">NemotronModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">NemotronModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel.run"><code class="docutils literal notranslate"><span class="pre">NemotronModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.nemotron_model.NemotronModel.token_counter"><code class="docutils literal notranslate"><span class="pre">NemotronModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.ollama_model">camel.models.ollama_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel"><code class="docutils literal notranslate"><span class="pre">OllamaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OllamaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.run"><code class="docutils literal notranslate"><span class="pre">OllamaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.stream"><code class="docutils literal notranslate"><span class="pre">OllamaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ollama_model.OllamaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OllamaModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.openai_audio_models">camel.models.open_source_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_audio_models.OpenAIAudioModels"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_audio_models.OpenAIAudioModels.speech_to_text"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.speech_to_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_audio_models.OpenAIAudioModels.text_to_speech"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.text_to_speech()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.openai_compatible_model">camel.models.openai_compatible_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_compatible_model.OpenAICompatibleModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.openai_model">camel.models.openai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel"><code class="docutils literal notranslate"><span class="pre">OpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.openai_model.OpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.reka_model">camel.models.reka_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel"><code class="docutils literal notranslate"><span class="pre">RekaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">RekaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.run"><code class="docutils literal notranslate"><span class="pre">RekaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.stream"><code class="docutils literal notranslate"><span class="pre">RekaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.reka_model.RekaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">RekaModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.samba_model">camel.models.samba_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel"><code class="docutils literal notranslate"><span class="pre">SambaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">SambaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.run"><code class="docutils literal notranslate"><span class="pre">SambaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.stream"><code class="docutils literal notranslate"><span class="pre">SambaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.samba_model.SambaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">SambaModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.stub_model">camel.models.stub_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel"><code class="docutils literal notranslate"><span class="pre">StubModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">StubModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.model_type"><code class="docutils literal notranslate"><span class="pre">StubModel.model_type</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.run"><code class="docutils literal notranslate"><span class="pre">StubModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubModel.token_counter"><code class="docutils literal notranslate"><span class="pre">StubModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubTokenCounter"><code class="docutils literal notranslate"><span class="pre">StubTokenCounter</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.stub_model.StubTokenCounter.count_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">StubTokenCounter.count_tokens_from_messages()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.togetherai_model">camel.models.togetherai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.run"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.stream"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.togetherai_model.TogetherAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.vllm_model">camel.models.vllm_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel"><code class="docutils literal notranslate"><span class="pre">VLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">VLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.run"><code class="docutils literal notranslate"><span class="pre">VLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.stream"><code class="docutils literal notranslate"><span class="pre">VLLMModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.vllm_model.VLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">VLLMModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models.zhipuai_model">camel.models.zhipuai_model module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.run"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.stream"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.zhipuai_model.ZhipuAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-camel.models">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel"><code class="docutils literal notranslate"><span class="pre">AnthropicModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.count_tokens_from_prompt"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.count_tokens_from_prompt()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.run"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.stream"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AnthropicModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AnthropicModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.AzureOpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.check_model_config"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.count_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.count_tokens_from_messages()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.run"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.stream"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.token_counter"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_counter</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.BaseModelBackend.token_limit"><code class="docutils literal notranslate"><span class="pre">BaseModelBackend.token_limit</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel"><code class="docutils literal notranslate"><span class="pre">GeminiModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GeminiModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.run"><code class="docutils literal notranslate"><span class="pre">GeminiModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.stream"><code class="docutils literal notranslate"><span class="pre">GeminiModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.to_gemini_req"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_gemini_req()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.to_openai_response"><code class="docutils literal notranslate"><span class="pre">GeminiModel.to_openai_response()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GeminiModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GeminiModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel"><code class="docutils literal notranslate"><span class="pre">GroqModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">GroqModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.run"><code class="docutils literal notranslate"><span class="pre">GroqModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.stream"><code class="docutils literal notranslate"><span class="pre">GroqModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.GroqModel.token_counter"><code class="docutils literal notranslate"><span class="pre">GroqModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel.run"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.LiteLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">LiteLLMModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel"><code class="docutils literal notranslate"><span class="pre">MistralModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">MistralModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.run"><code class="docutils literal notranslate"><span class="pre">MistralModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.stream"><code class="docutils literal notranslate"><span class="pre">MistralModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.MistralModel.token_counter"><code class="docutils literal notranslate"><span class="pre">MistralModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ModelFactory"><code class="docutils literal notranslate"><span class="pre">ModelFactory</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ModelFactory.create"><code class="docutils literal notranslate"><span class="pre">ModelFactory.create()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel"><code class="docutils literal notranslate"><span class="pre">NemotronModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">NemotronModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel.run"><code class="docutils literal notranslate"><span class="pre">NemotronModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.NemotronModel.token_counter"><code class="docutils literal notranslate"><span class="pre">NemotronModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel"><code class="docutils literal notranslate"><span class="pre">OllamaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OllamaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.run"><code class="docutils literal notranslate"><span class="pre">OllamaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.stream"><code class="docutils literal notranslate"><span class="pre">OllamaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OllamaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OllamaModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIAudioModels"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIAudioModels.speech_to_text"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.speech_to_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIAudioModels.text_to_speech"><code class="docutils literal notranslate"><span class="pre">OpenAIAudioModels.text_to_speech()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAICompatibleModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel"><code class="docutils literal notranslate"><span class="pre">OpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.run"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.stream"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.OpenAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel"><code class="docutils literal notranslate"><span class="pre">QwenModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">QwenModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.run"><code class="docutils literal notranslate"><span class="pre">QwenModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.stream"><code class="docutils literal notranslate"><span class="pre">QwenModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.QwenModel.token_counter"><code class="docutils literal notranslate"><span class="pre">QwenModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel"><code class="docutils literal notranslate"><span class="pre">RekaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">RekaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.run"><code class="docutils literal notranslate"><span class="pre">RekaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.stream"><code class="docutils literal notranslate"><span class="pre">RekaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.RekaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">RekaModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel"><code class="docutils literal notranslate"><span class="pre">SambaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">SambaModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.run"><code class="docutils literal notranslate"><span class="pre">SambaModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.stream"><code class="docutils literal notranslate"><span class="pre">SambaModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.SambaModel.token_counter"><code class="docutils literal notranslate"><span class="pre">SambaModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel"><code class="docutils literal notranslate"><span class="pre">StubModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">StubModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.model_type"><code class="docutils literal notranslate"><span class="pre">StubModel.model_type</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.run"><code class="docutils literal notranslate"><span class="pre">StubModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.StubModel.token_counter"><code class="docutils literal notranslate"><span class="pre">StubModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.run"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.stream"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.TogetherAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">TogetherAIModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel"><code class="docutils literal notranslate"><span class="pre">VLLMModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">VLLMModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.run"><code class="docutils literal notranslate"><span class="pre">VLLMModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.stream"><code class="docutils literal notranslate"><span class="pre">VLLMModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.VLLMModel.token_counter"><code class="docutils literal notranslate"><span class="pre">VLLMModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel"><code class="docutils literal notranslate"><span class="pre">YiModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">YiModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.run"><code class="docutils literal notranslate"><span class="pre">YiModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.stream"><code class="docutils literal notranslate"><span class="pre">YiModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.YiModel.token_counter"><code class="docutils literal notranslate"><span class="pre">YiModel.token_counter</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.check_model_config"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.check_model_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.run"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.run()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.stream"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.stream</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#camel.models.ZhipuAIModel.token_counter"><code class="docutils literal notranslate"><span class="pre">ZhipuAIModel.token_counter</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By CAMEL-AI.org
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2024, CAMEL-AI.org.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>